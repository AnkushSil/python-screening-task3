## Research Plan

To evaluate open-source AI models for student competence analysis in Python, I first identified models capable of analyzing code, such as StarCoder2-3B from Hugging Face. My approach was to test each model's ability to understand Python syntax, generate meaningful prompts, and highlight reasoning gaps without giving away the solution. I used Google Colab for rapid experimentation, applying the models to multiple student code snippets and comparing the generated analysis with expected conceptual understanding.

I validated the model's applicability by checking the relevance, accuracy, and clarity of the outputs. I also ensured that the feedback was structured into summaries, core concepts, misconceptions, hints, and competence scores. Based on this evaluation, I determined that StarCoder2-3B provides consistent, interpretable outputs suitable for high-level competence analysis in Python.
